{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from openai import AzureOpenAI\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chat_llms import *\n",
    "from utils import *\n",
    "\n",
    "import importlib\n",
    "import prompts\n",
    "importlib.reload(prompts)\n",
    "from revised_prompts import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = creat_llm()\n",
    "run_id_str = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_slc_prompt(original_prompt, input_dict={}, num_comparison_choices=3):\n",
    "    # get original output\n",
    "    slc_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            ('system', original_prompt),\n",
    "            ('human', scenario_library_creation_task_prompt),\n",
    "        ]\n",
    "    )\n",
    "    slc_model = slc_prompt | llm\n",
    "    scenario_library_output = slc_model.invoke(input_dict)\n",
    "    scenario_library = scenario_library_output.content\n",
    "    # critic -> comments\n",
    "    slc_critic_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            ('system', slc_critic_system_prompt),\n",
    "            ('human', slc_critic_task_prompt),\n",
    "        ]\n",
    "    )\n",
    "    slc_critic = slc_critic_prompt | llm\n",
    "    slc_critic_output = slc_critic.invoke({'scenario_library': scenario_library})\n",
    "    slc_comments = slc_critic_output.content\n",
    "    # refiner -> refined prompt\n",
    "    slc_refiner_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            ('system', slc_refiner_system_prompt),\n",
    "            ('human', slc_refiner_task_prompt),\n",
    "        ]\n",
    "    )\n",
    "    slc_refiner = slc_refiner_prompt | llm\n",
    "    refined_prompt_output = slc_refiner.invoke({'original_prompt': original_prompt, 'scenario_library': scenario_library, 'critic_comments': slc_comments})\n",
    "    refined_prompt = refined_prompt_output.content\n",
    "    # get refined output\n",
    "    slc_refined_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            ('system', refined_prompt),\n",
    "            ('human', scenario_library_creation_task_prompt),\n",
    "        ]\n",
    "    )\n",
    "    slc_refined_model = slc_refined_prompt | llm\n",
    "    refined_scenario_library_output = slc_refined_model.invoke(input_dict)\n",
    "    refined_scenario_library = refined_scenario_library_output.content\n",
    "    refined_slc_critic_output = slc_critic.invoke({'scenario_library': refined_scenario_library})\n",
    "    refined_slc_comments = refined_slc_critic_output.content\n",
    "    # pairwise comparison\n",
    "    slc_comparison_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            ('system', slc_comparison_system_prompt),\n",
    "            ('human', slc_comparison_task_prompt),\n",
    "        ]\n",
    "    )\n",
    "    slc_comparison_model = slc_comparison_prompt | llm\n",
    "    input_dict_for_comparison = {\n",
    "        'slc_critic_system_prompt': slc_critic_system_prompt,\n",
    "        'scenario_library_a': scenario_library,\n",
    "        'scenario_library_b': refined_scenario_library,\n",
    "    }\n",
    "    comparison_better_list = []\n",
    "    comparison_degree_list = []\n",
    "    comparison_analysis_list = []\n",
    "    for i in range(num_comparison_choices):\n",
    "        comparison_analysis = slc_comparison_model.invoke(input_dict_for_comparison)\n",
    "        comparison_analysis = comparison_analysis.content\n",
    "        comparison_analysis_list.append(comparison_analysis)\n",
    "        try:\n",
    "            comparison_analysis_dict = json.loads(comparison_analysis)\n",
    "        except:\n",
    "            print(comparison_analysis)\n",
    "        comparison_better_list.append(comparison_analysis_dict['better'])\n",
    "        comparison_degree_list.append(comparison_analysis_dict['degree'])\n",
    "    overall_better = max(set(comparison_better_list), key=comparison_better_list.count)\n",
    "    average_degree = sum(comparison_degree_list) / len(comparison_degree_list)\n",
    "    return {\n",
    "        'original_prompt': original_prompt,\n",
    "        'refined_prompt': refined_prompt,\n",
    "        'overall_better': overall_better,\n",
    "        'average_degree': average_degree,\n",
    "        'scenario_library': safe_json_loads(scenario_library),\n",
    "        'refined_scenario_library': safe_json_loads(refined_scenario_library),\n",
    "        'critic_comments': safe_json_loads(slc_comments),\n",
    "        'refined_critic_comments': safe_json_loads(refined_slc_comments),\n",
    "        'comparison_analysis_list': [safe_json_loads(comparison_analysis) for comparison_analysis in comparison_analysis_list],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info = 'Programmer, Junior'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Input to ChatPromptTemplate is missing variables {\"\\\\n    \\'scenes\\'\"}.  Expected: [\"\\\\n    \\'scenes\\'\", \\'user_info\\'] Received: [\\'user_info\\']\\nNote: if you intended {\\n    \\'scenes\\'} to be part of the string and not a variable, please escape it with double curly braces like: \\'{{\\n    \\'scenes\\'}}\\'.'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# runtime_str = datetime.datetime.now().strftime('%Y%m%d%-H%M%S')\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m round_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_refinement_rounds):\n\u001b[1;32m---> 10\u001b[0m     refinement_results \u001b[38;5;241m=\u001b[39m \u001b[43mrefine_slc_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     refinement_results_list\u001b[38;5;241m.\u001b[39mappend(refinement_results)\n\u001b[0;32m     13\u001b[0m     refinement_results_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults/slc_refinement_results_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mround_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_id_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "Cell \u001b[1;32mIn[34], line 10\u001b[0m, in \u001b[0;36mrefine_slc_prompt\u001b[1;34m(original_prompt, input_dict, num_comparison_choices)\u001b[0m\n\u001b[0;32m      3\u001b[0m slc_prompt \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_messages(\n\u001b[0;32m      4\u001b[0m     [\n\u001b[0;32m      5\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m'\u001b[39m, original_prompt),\n\u001b[0;32m      6\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m'\u001b[39m, scenario_library_creation_task_prompt),\n\u001b[0;32m      7\u001b[0m     ]\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m      9\u001b[0m slc_model \u001b[38;5;241m=\u001b[39m slc_prompt \u001b[38;5;241m|\u001b[39m llm\n\u001b[1;32m---> 10\u001b[0m scenario_library_output \u001b[38;5;241m=\u001b[39m \u001b[43mslc_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m scenario_library \u001b[38;5;241m=\u001b[39m scenario_library_output\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# critic -> comments\u001b[39;00m\n",
      "File \u001b[1;32md:\\VSCode_Porgrams\\eqbot\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2876\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   2874\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m   2875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2876\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2877\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2878\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32md:\\VSCode_Porgrams\\eqbot\\venv\\Lib\\site-packages\\langchain_core\\prompts\\base.py:186\u001b[0m, in \u001b[0;36mBasePromptTemplate.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags:\n\u001b[0;32m    185\u001b[0m     config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags\n\u001b[1;32m--> 186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_prompt_with_error_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\VSCode_Porgrams\\eqbot\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1785\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m   1782\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[0;32m   1783\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   1784\u001b[0m         Output,\n\u001b[1;32m-> 1785\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1786\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1787\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1788\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1789\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1791\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1792\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1793\u001b[0m     )\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1795\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32md:\\VSCode_Porgrams\\eqbot\\venv\\Lib\\site-packages\\langchain_core\\runnables\\config.py:398\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    397\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\VSCode_Porgrams\\eqbot\\venv\\Lib\\site-packages\\langchain_core\\prompts\\base.py:160\u001b[0m, in \u001b[0;36mBasePromptTemplate._format_prompt_with_error_handling\u001b[1;34m(self, inner_input)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_format_prompt_with_error_handling\u001b[39m(\u001b[38;5;28mself\u001b[39m, inner_input: Dict) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PromptValue:\n\u001b[1;32m--> 160\u001b[0m     _inner_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_prompt(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_inner_input)\n",
      "File \u001b[1;32md:\\VSCode_Porgrams\\eqbot\\venv\\Lib\\site-packages\\langchain_core\\prompts\\base.py:156\u001b[0m, in \u001b[0;36mBasePromptTemplate._validate_input\u001b[1;34m(self, inner_input)\u001b[0m\n\u001b[0;32m    150\u001b[0m     example_key \u001b[38;5;241m=\u001b[39m missing\u001b[38;5;241m.\u001b[39mpop()\n\u001b[0;32m    151\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    152\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNote: if you intended \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m to be part of the string\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    153\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and not a variable, please escape it with double curly braces like: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    154\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    155\u001b[0m     )\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(msg)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inner_input\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Input to ChatPromptTemplate is missing variables {\"\\\\n    \\'scenes\\'\"}.  Expected: [\"\\\\n    \\'scenes\\'\", \\'user_info\\'] Received: [\\'user_info\\']\\nNote: if you intended {\\n    \\'scenes\\'} to be part of the string and not a variable, please escape it with double curly braces like: \\'{{\\n    \\'scenes\\'}}\\'.'"
     ]
    }
   ],
   "source": [
    "input_dict = {'user_info': user_info}\n",
    "original_prompt = scenario_library_creation_original_system_prompt\n",
    "\n",
    "max_refinement_rounds = 10\n",
    "refinement_results_list = []\n",
    "average_degree_list = []\n",
    "overall_better_list = []\n",
    "# runtime_str = datetime.datetime.now().strftime('%Y%m%d%-H%M%S')\n",
    "for round_id in range(max_refinement_rounds):\n",
    "    refinement_results = refine_slc_prompt(original_prompt, input_dict)\n",
    "    refinement_results_list.append(refinement_results)\n",
    "\n",
    "    refinement_results_file_path = f'results/slc_refinement_results_{round_id}_{run_id_str}.json'\n",
    "    save_json(refinement_results_file_path, refinement_results)\n",
    "\n",
    "    overall_better_list.append(refinement_results['overall_better'])\n",
    "    average_degree_list.append(refinement_results['average_degree'])\n",
    "\n",
    "    print(f'Round {round_id}: Prompt {refinement_results[\"overall_better\"]} is better ({refinement_results[\"average_degree\"]})')\n",
    "    if refinement_results['overall_better'] == 1:\n",
    "        original_prompt = refinement_results['refined_prompt']\n",
    "\n",
    "    if round_id >= 3:\n",
    "        latest_dedup_overall_better_list = list(set(overall_better_list[-3:]))\n",
    "        if len(latest_dedup_overall_better_list) == 1 and latest_dedup_overall_better_list[0] == 0:\n",
    "            break\n",
    "        latest_dedup_average_degree_list = list(set(average_degree_list[-3:]))\n",
    "        if len(latest_dedup_average_degree_list) == 1 and latest_dedup_average_degree_list[0] <= 0:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
